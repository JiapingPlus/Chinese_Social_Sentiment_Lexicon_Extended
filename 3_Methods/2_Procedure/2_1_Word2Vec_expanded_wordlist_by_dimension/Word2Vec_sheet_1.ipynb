{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预训练的词向量语料库文件路径\n",
    "tecent_embedding_path = (r'D:\\embedding_zh\\tencent-ailab-embedding-zh-d200-v0.2.0-s\\tencent-ailab-embedding-zh-d200-v0.2.0-s.txt')\n",
    "\n",
    "# 加载词向量文件\n",
    "tencent_embedding = models.KeyedVectors.load_word2vec_format(tecent_embedding_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入读取数据所需要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "\n",
    "df = read_excel(r'data\\SEV_wordlist.xlsx')\n",
    "# 查看数据的形状\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>App_Dim_mean</th>\n",
       "      <th>App_Dim_sd</th>\n",
       "      <th>SES_Dim_mean</th>\n",
       "      <th>SES_Dim_sd</th>\n",
       "      <th>Soc_Dim_mean</th>\n",
       "      <th>Soc_Dim_sd</th>\n",
       "      <th>Com_Dim_mean</th>\n",
       "      <th>Com_Dim_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>Val_sd</th>\n",
       "      <th>Valence</th>\n",
       "      <th>N_raters</th>\n",
       "      <th>N_App</th>\n",
       "      <th>N_SES</th>\n",
       "      <th>N_Soc</th>\n",
       "      <th>N_Com</th>\n",
       "      <th>N_Mor</th>\n",
       "      <th>N_Non</th>\n",
       "      <th>N_Amb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>美</td>\n",
       "      <td>Appearance</td>\n",
       "      <td>8.822</td>\n",
       "      <td>0.736</td>\n",
       "      <td>2.425234</td>\n",
       "      <td>2.009723</td>\n",
       "      <td>2.242991</td>\n",
       "      <td>1.992197</td>\n",
       "      <td>2.780374</td>\n",
       "      <td>2.505091</td>\n",
       "      <td>...</td>\n",
       "      <td>1.123</td>\n",
       "      <td>Positive</td>\n",
       "      <td>214</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>帅</td>\n",
       "      <td>Appearance</td>\n",
       "      <td>8.795</td>\n",
       "      <td>0.940</td>\n",
       "      <td>2.120930</td>\n",
       "      <td>1.883097</td>\n",
       "      <td>2.669767</td>\n",
       "      <td>2.351728</td>\n",
       "      <td>2.762791</td>\n",
       "      <td>2.421576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.281</td>\n",
       "      <td>Positive</td>\n",
       "      <td>215</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>漂亮</td>\n",
       "      <td>Appearance</td>\n",
       "      <td>8.740</td>\n",
       "      <td>1.109</td>\n",
       "      <td>2.781395</td>\n",
       "      <td>2.356861</td>\n",
       "      <td>3.246512</td>\n",
       "      <td>2.584945</td>\n",
       "      <td>3.390698</td>\n",
       "      <td>2.711331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260</td>\n",
       "      <td>Positive</td>\n",
       "      <td>215</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>好看</td>\n",
       "      <td>Appearance</td>\n",
       "      <td>8.701</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.957944</td>\n",
       "      <td>1.715192</td>\n",
       "      <td>2.028037</td>\n",
       "      <td>1.738587</td>\n",
       "      <td>2.364486</td>\n",
       "      <td>2.238764</td>\n",
       "      <td>...</td>\n",
       "      <td>1.256</td>\n",
       "      <td>Positive</td>\n",
       "      <td>214</td>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>美丽</td>\n",
       "      <td>Appearance</td>\n",
       "      <td>8.668</td>\n",
       "      <td>1.255</td>\n",
       "      <td>2.126168</td>\n",
       "      <td>1.812312</td>\n",
       "      <td>2.130841</td>\n",
       "      <td>1.838984</td>\n",
       "      <td>2.331776</td>\n",
       "      <td>2.073128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.201</td>\n",
       "      <td>Positive</td>\n",
       "      <td>214</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word   Dimension  App_Dim_mean  App_Dim_sd  SES_Dim_mean  SES_Dim_sd  \\\n",
       "0    美  Appearance         8.822       0.736      2.425234    2.009723   \n",
       "1    帅  Appearance         8.795       0.940      2.120930    1.883097   \n",
       "2   漂亮  Appearance         8.740       1.109      2.781395    2.356861   \n",
       "3   好看  Appearance         8.701       0.942      1.957944    1.715192   \n",
       "4   美丽  Appearance         8.668       1.255      2.126168    1.812312   \n",
       "\n",
       "   Soc_Dim_mean  Soc_Dim_sd  Com_Dim_mean  Com_Dim_sd  ...  Val_sd   Valence  \\\n",
       "0      2.242991    1.992197      2.780374    2.505091  ...   1.123  Positive   \n",
       "1      2.669767    2.351728      2.762791    2.421576  ...   1.281  Positive   \n",
       "2      3.246512    2.584945      3.390698    2.711331  ...   1.260  Positive   \n",
       "3      2.028037    1.738587      2.364486    2.238764  ...   1.256  Positive   \n",
       "4      2.130841    1.838984      2.331776    2.073128  ...   1.201  Positive   \n",
       "\n",
       "   N_raters  N_App N_SES  N_Soc  N_Com  N_Mor  N_Non  N_Amb  \n",
       "0       214    182     1      0      1      3      0     27  \n",
       "1       215    193     0      1      0      0      2     19  \n",
       "2       215    189     1      1      1      0      3     20  \n",
       "3       214    201     2      0      0      0      1     10  \n",
       "4       214    191     0      1      1      2      4     15  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据前五行\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     美\n",
       "1     帅\n",
       "2    漂亮\n",
       "3    好看\n",
       "4    美丽\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求积极词汇的词表\n",
    "df_positive = df.loc[df['Valence']=='Positive', 'Word']\n",
    "df_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['美',\n",
       " '帅',\n",
       " '漂亮',\n",
       " '好看',\n",
       " '美丽',\n",
       " '天香国色',\n",
       " '花容月貌',\n",
       " '天姿国色',\n",
       " '帅气',\n",
       " '眉清目秀',\n",
       " '美女',\n",
       " '俊美',\n",
       " '苗条',\n",
       " '耐看',\n",
       " '俊秀',\n",
       " '俊俏',\n",
       " '靓女',\n",
       " '靓丽',\n",
       " '英俊',\n",
       " '白净',\n",
       " '可爱',\n",
       " '沉鱼落雁',\n",
       " '迷人',\n",
       " '亭亭玉立',\n",
       " '清秀',\n",
       " '白',\n",
       " '俏丽',\n",
       " '国色天香',\n",
       " '美貌',\n",
       " '高挑儿',\n",
       " '妩媚',\n",
       " '闭月羞花',\n",
       " '清纯',\n",
       " '性感',\n",
       " '高大',\n",
       " '细嫩',\n",
       " '童颜鹤发',\n",
       " '惊艳',\n",
       " '面善',\n",
       " '丰腴',\n",
       " '甜美',\n",
       " '一表人才',\n",
       " '强壮',\n",
       " '婀娜',\n",
       " '女神',\n",
       " '文质彬彬',\n",
       " '鹤发童颜',\n",
       " '健壮',\n",
       " '干净',\n",
       " '秀色可餐',\n",
       " '圆润',\n",
       " '挺拔',\n",
       " '柔美',\n",
       " '身强力壮',\n",
       " '西施',\n",
       " '姣好',\n",
       " '娇艳',\n",
       " '年轻',\n",
       " '光彩照人',\n",
       " '壮实',\n",
       " '匀称',\n",
       " '光鲜',\n",
       " '笔挺',\n",
       " '小巧玲珑',\n",
       " '端庄',\n",
       " '精致',\n",
       " '壮健',\n",
       " '阳光',\n",
       " '稚气',\n",
       " '骨感',\n",
       " '明眸皓齿',\n",
       " '魅力',\n",
       " '衣冠楚楚',\n",
       " '顺眼',\n",
       " '斯文',\n",
       " '风华正茂',\n",
       " '娇柔',\n",
       " '精壮',\n",
       " '淑女',\n",
       " '粗壮',\n",
       " '威猛',\n",
       " '雪白',\n",
       " '秀外慧中',\n",
       " '强健',\n",
       " '书生气',\n",
       " '温文尔雅',\n",
       " '珠圆玉润',\n",
       " '时髦',\n",
       " '整洁',\n",
       " '明眸',\n",
       " '慈祥',\n",
       " '彪悍',\n",
       " '倜傥',\n",
       " '优雅',\n",
       " '俏皮',\n",
       " '剽悍',\n",
       " '文静',\n",
       " '素雅',\n",
       " '雍容',\n",
       " '儒雅',\n",
       " '憨厚',\n",
       " '憨实',\n",
       " '玉洁冰清',\n",
       " '饱经风霜',\n",
       " '结实',\n",
       " '阳刚',\n",
       " '硬朗',\n",
       " '气质',\n",
       " '上相',\n",
       " '飒爽',\n",
       " '优美',\n",
       " '健美',\n",
       " '文雅',\n",
       " '清新',\n",
       " '冰清玉洁',\n",
       " '和蔼',\n",
       " '时尚',\n",
       " '英武',\n",
       " '文气',\n",
       " '乖巧',\n",
       " '朝气',\n",
       " '精神',\n",
       " '正点',\n",
       " '神气',\n",
       " '典雅',\n",
       " '意气风发',\n",
       " '恬静',\n",
       " '朴素',\n",
       " '威武',\n",
       " '独特',\n",
       " '短小精悍',\n",
       " '灵透',\n",
       " '柔和',\n",
       " '吉人天相',\n",
       " '凝脂',\n",
       " '敦实',\n",
       " '霸气',\n",
       " '像样',\n",
       " '娴静',\n",
       " '温柔',\n",
       " '灵性',\n",
       " '纯真',\n",
       " '憨直',\n",
       " '钟灵毓秀',\n",
       " '健朗',\n",
       " '威严',\n",
       " '奇特',\n",
       " '健康',\n",
       " '诱人',\n",
       " '目光如炬',\n",
       " '文绉绉',\n",
       " '单纯',\n",
       " '慈爱',\n",
       " '赶时髦',\n",
       " '严肃',\n",
       " '血气方刚',\n",
       " '微笑',\n",
       " '粗豪']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 格式转化为列表\n",
    "positive_word_list = df_positive.tolist()\n",
    "positive_word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 高挑儿...\n"
     ]
    }
   ],
   "source": [
    "# 初始化有效种子词列表和相似词列表\n",
    "positive_word_list_effective = []\n",
    "similar_words_list = []\n",
    "\n",
    "# 过滤词向量模型中存在的词并生成相似词\n",
    "for word in positive_word_list:\n",
    "    if word in tencent_embedding:\n",
    "        positive_word_list_effective.append(word)\n",
    "        # 找到与该词最相似的 10 个词\n",
    "        similar_words = tencent_embedding.most_similar(word, topn=10)\n",
    "        # 将相似词加入列表\n",
    "        for similar_word, similarity in similar_words:\n",
    "            similar_words_list.append(similar_word)\n",
    "    else:\n",
    "        print(f\"Skipping {word}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Word\n",
      "0       的美\n",
      "1       美的\n",
      "2       和美\n",
      "3       叫美\n",
      "4        丽\n",
      "...    ...\n",
      "1565    虬髯\n",
      "1566  黑脸汉子\n",
      "1567  中年汉子\n",
      "1568    莽汉\n",
      "1569    魁伟\n",
      "\n",
      "[1570 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 将生成的积极相似词先转换为 DataFrame，查看是否生成成功\n",
    "df_similar_words = pd.DataFrame(similar_words_list, columns=['Word'])\n",
    "print(df_similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将相似词列表转换为集合再转换回列表，以去掉重复出现的词\n",
    "unique_similar_words_list = list(set(similar_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Word\n",
      "0       厚实\n",
      "1     仙风道骨\n",
      "2     阳刚之美\n",
      "3       威猛\n",
      "4       精美\n",
      "...    ...\n",
      "1238    清丽\n",
      "1239    有型\n",
      "1240  蕙质兰心\n",
      "1241  青春正好\n",
      "1242  长得英俊\n",
      "\n",
      "[1243 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 将去重后的结果转换为 DataFrame\n",
    "df_unique_similar_words = pd.DataFrame(unique_similar_words_list, columns=['Word'])\n",
    "print(df_unique_similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存去重后的相似词表到excel文件\n",
    "df_unique_similar_words.to_excel(r'result\\positive_similar_words_unique.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面做消极词汇的表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158       丑\n",
       "159       胖\n",
       "160      黢黑\n",
       "161      丑陋\n",
       "162    胡子拉碴\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求消极词汇的词表\n",
    "df_negative = df.loc[df['Valence']=='Negative', 'Word']\n",
    "df_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['丑',\n",
       " '胖',\n",
       " '黢黑',\n",
       " '丑陋',\n",
       " '胡子拉碴',\n",
       " '丑八怪',\n",
       " '矮小',\n",
       " '难看',\n",
       " '肥胖',\n",
       " '膀大腰圆',\n",
       " '面黄肌瘦',\n",
       " '矮',\n",
       " '黑黢黢',\n",
       " '瘦小',\n",
       " '黑黝黝',\n",
       " '苍老',\n",
       " '秃顶',\n",
       " '其貌不扬',\n",
       " '消瘦',\n",
       " '黑',\n",
       " '妖艳',\n",
       " '贼眉鼠眼',\n",
       " '蓬头垢面',\n",
       " '尖嘴猴腮',\n",
       " '瘦弱',\n",
       " '驼背',\n",
       " '妖媚',\n",
       " '虎背熊腰',\n",
       " '娇媚',\n",
       " '浓艳',\n",
       " '灰头土脸',\n",
       " '邋遢',\n",
       " '皱纹',\n",
       " '纤弱',\n",
       " '憔悴',\n",
       " '娇娆',\n",
       " '土气',\n",
       " '老气',\n",
       " '凶巴巴',\n",
       " '娇滴滴',\n",
       " '獐头鼠目',\n",
       " '油腻',\n",
       " '不修边幅',\n",
       " '青面獠牙',\n",
       " '狰狞',\n",
       " '凶恶',\n",
       " '丑恶',\n",
       " '贼头贼脑',\n",
       " '粗犷',\n",
       " '弱不禁风',\n",
       " '凶悍',\n",
       " '艳俗',\n",
       " '囚首垢面',\n",
       " '风骚',\n",
       " '文弱',\n",
       " '呆头呆脑',\n",
       " '孱弱',\n",
       " '慓悍',\n",
       " '呆傻',\n",
       " '凶狠',\n",
       " '病弱',\n",
       " '凶横',\n",
       " '阴柔',\n",
       " '脏',\n",
       " '魅惑',\n",
       " '冷若冰霜',\n",
       " '老气横秋',\n",
       " '尖嘴',\n",
       " '傻乎乎',\n",
       " '可怕',\n",
       " '弱小',\n",
       " '病态',\n",
       " '愣头愣脑',\n",
       " '凶猛',\n",
       " '羞羞答答',\n",
       " '冷酷',\n",
       " '呆滞',\n",
       " '虚弱',\n",
       " '呆板',\n",
       " '恶煞',\n",
       " '奇怪',\n",
       " '褴褛',\n",
       " '冷傲',\n",
       " '清冷',\n",
       " '羸弱',\n",
       " '无精打采',\n",
       " '病病歪歪',\n",
       " '媚俗',\n",
       " '古怪',\n",
       " '傻呵呵',\n",
       " '阴郁',\n",
       " '粗糙',\n",
       " '阴沉',\n",
       " '凶狂',\n",
       " '萎靡',\n",
       " '野性',\n",
       " '死气沉沉',\n",
       " '滑稽']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 格式转化为列表\n",
    "negative_word_list = df_negative.tolist()\n",
    "negative_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 囚首垢面...\n",
      "Skipping 慓悍...\n",
      "Skipping 病病歪歪...\n"
     ]
    }
   ],
   "source": [
    "# 初始化有效种子词列表和相似词列表\n",
    "negative_word_list_effective = []\n",
    "similar_negative_words_list = []\n",
    "\n",
    "# 过滤词向量模型中存在的词并生成相似词\n",
    "for word in negative_word_list:\n",
    "    if word in tencent_embedding:\n",
    "        negative_word_list_effective.append(word)\n",
    "        # 找到与该词最相似的 10 个词\n",
    "        similar_negative_words = tencent_embedding.most_similar(word, topn=10)\n",
    "        # 将相似词加入列表\n",
    "        for similar_negative_word, similarity in similar_negative_words:\n",
    "            similar_negative_words_list.append(similar_negative_word)\n",
    "    else:\n",
    "        print(f\"Skipping {word}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Word\n",
      "0      丑的\n",
      "1     长得丑\n",
      "2     长的丑\n",
      "3    长得难看\n",
      "4      不丑\n",
      "..    ...\n",
      "945  惹人发笑\n",
      "946    可笑\n",
      "947  十分好笑\n",
      "948  引人发笑\n",
      "949    发噱\n",
      "\n",
      "[950 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 将生成的积极相似词先转换为 DataFrame，查看是否生成成功\n",
    "df_similar_negative_words = pd.DataFrame(similar_negative_words_list, columns=['Word'])\n",
    "print(df_similar_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将相似词列表转换为集合再转换回列表，以去掉重复出现的词\n",
    "unique_similar_negative_words_list = list(set(similar_negative_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Word\n",
      "0     黑黢黢\n",
      "1    凶悍无比\n",
      "2    流里流气\n",
      "3      悍勇\n",
      "4    满脸胡茬\n",
      "..    ...\n",
      "734    单薄\n",
      "735   板着脸\n",
      "736  脸色憔悴\n",
      "737  牛高马大\n",
      "738  傻不拉几\n",
      "\n",
      "[739 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 将去重后的结果转换为 DataFrame\n",
    "df_unique_similar_negative_words = pd.DataFrame(unique_similar_negative_words_list, columns=['Word'])\n",
    "print(df_unique_similar_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存去重后的相似词表到excel文件\n",
    "df_unique_similar_negative_words.to_excel(r'result\\negative_similar_words_unique.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
